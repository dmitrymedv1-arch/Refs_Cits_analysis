import streamlit as st
import pandas as pd
import requests
import time
from typing import List, Dict, Any, Tuple
import re
from collections import Counter
import tempfile
import os
import concurrent.futures
from functools import lru_cache
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
st.set_page_config(
    page_title="Refs/Cits Analysis",
    page_icon="üìö",
    layout="wide"
)

class FastCitationAnalyzer:
    def __init__(self):
        self.request_delay = 0.2  # –£–º–µ–Ω—å—à–∏–ª–∏ –∑–∞–¥–µ—Ä–∂–∫—É
        self.max_dois = 50
        self.max_references_per_article = 20  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
        self.max_citations_per_article = 20
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Academic-Analyzer/1.0 (mailto:example@university.edu)',
            'Accept': 'application/json'
        })
        
        # –ö–µ—à–∏
        self._crossref_cache = {}
        self._openalex_cache = {}
        self._article_data_cache = {}

    def validate_doi(self, doi: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å DOI"""
        if not doi or not isinstance(doi, str):
            return False
            
        doi = self.normalize_doi(doi)
        doi_pattern = r'^10\.\d{4,9}/[-._;()/:a-zA-Z0-9]+$'
        
        return bool(re.match(doi_pattern, doi, re.IGNORECASE))
    
    def normalize_doi(self, doi: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç DOI"""
        if not doi or not isinstance(doi, str):
            return ""
            
        doi = doi.strip()
        prefixes = [
            'https://doi.org/', 'http://doi.org/', 'doi.org/',
            'doi:', 'DOI:', 'https://dx.doi.org/', 'http://dx.doi.org/',
        ]
        
        for prefix in prefixes:
            if doi.lower().startswith(prefix.lower()):
                doi = doi[len(prefix):]
                break
                
        doi = doi.split('?')[0].split('#')[0]
        return doi.strip().lower()
    
    def parse_doi_input(self, input_text: str) -> List[str]:
        """–ü–∞—Ä—Å–∏—Ç –≤–≤–æ–¥ DOI"""
        if not input_text or not isinstance(input_text, str):
            return []
            
        lines = input_text.strip().split('\n')
        dois = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            line = line.rstrip('.,;')
            doi_pattern = r'10\.\d{4,9}/[-._;()/:a-zA-Z0-9]+'
            found_dois = re.findall(doi_pattern, line, re.IGNORECASE)
            
            if found_dois:
                dois.extend(found_dois)
            else:
                if 'doi.org/' in line.lower():
                    doi_part = line.lower().split('doi.org/')[-1]
                    doi_part = doi_part.split('?')[0].split('#')[0].strip()
                    if self.validate_doi(doi_part):
                        dois.append(doi_part)
                elif self.validate_doi(line):
                    dois.append(line)
        
        # –û—á–∏—Å—Ç–∫–∞ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        cleaned_dois = []
        seen = set()
        for doi in dois:
            normalized_doi = self.normalize_doi(doi)
            if self.validate_doi(normalized_doi) and normalized_doi not in seen:
                seen.add(normalized_doi)
                cleaned_dois.append(normalized_doi)
                
        return cleaned_dois[:self.max_dois]
    
    def get_crossref_data_batch(self, dois: List[str]) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Crossref –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö DOI —Å—Ä–∞–∑—É"""
        results = {}
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –≥—Ä—É–ø–ø—ã –ø–æ 10 DOI –¥–ª—è batch –∑–∞–ø—Ä–æ—Å–∞
        for i in range(0, len(dois), 10):
            batch_dois = dois[i:i+10]
            
            # Crossref –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ batch –∑–∞–ø—Ä–æ—Å—ã, –Ω–æ –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å
            # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_doi = {
                    executor.submit(self._get_single_crossref_data, doi): doi 
                    for doi in batch_dois
                }
                
                for future in concurrent.futures.as_completed(future_to_doi):
                    doi = future_to_doi[future]
                    try:
                        data = future.result()
                        results[doi] = data
                    except Exception as e:
                        st.warning(f"Error fetching Crossref data for {doi}: {e}")
                        results[doi] = {}
            
            time.sleep(self.request_delay)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
        
        return results
    
    def _get_single_crossref_data(self, doi: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ DOI –∏–∑ Crossref"""
        if doi in self._crossref_cache:
            return self._crossref_cache[doi]
            
        try:
            url = f"https://api.crossref.org/works/{doi}"
            response = self.session.get(url, timeout=15)
            if response.status_code == 200:
                data = response.json().get('message', {})
                self._crossref_cache[doi] = data
                return data
        except Exception as e:
            st.warning(f"Crossref error for {doi}: {e}")
            
        return {}
    
    def get_openalex_data_batch(self, dois: List[str]) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ OpenAlex –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö DOI —Å—Ä–∞–∑—É"""
        results = {}
        
        # OpenAlex –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º DOI
        doi_filter = "|".join([f"https://doi.org/{doi}" for doi in dois])
        url = f"https://api.openalex.org/works?filter=doi:{doi_filter}&per-page=50"
        
        try:
            response = self.session.get(url, timeout=20)
            if response.status_code == 200:
                data = response.json()
                works = data.get('results', [])
                
                # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ DOI -> –¥–∞–Ω–Ω—ã–µ
                for work in works:
                    if work.get('doi'):
                        clean_doi = self.normalize_doi(work['doi'])
                        self._openalex_cache[clean_doi] = work
                        results[clean_doi] = work
            
            # –î–ª—è DOI, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ batch –æ—Ç–≤–µ—Ç–µ, –¥–µ–ª–∞–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            missing_dois = set(dois) - set(results.keys())
            if missing_dois:
                with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                    future_to_doi = {
                        executor.submit(self._get_single_openalex_data, doi): doi 
                        for doi in missing_dois
                    }
                    
                    for future in concurrent.futures.as_completed(future_to_doi):
                        doi = future_to_doi[future]
                        try:
                            data = future.result()
                            results[doi] = data
                        except Exception:
                            results[doi] = {}
                            
        except Exception as e:
            st.warning(f"OpenAlex batch error: {e}")
            # Fallback –∫ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–∞–º
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_doi = {
                    executor.submit(self._get_single_openalex_data, doi): doi 
                    for doi in dois
                }
                
                for future in concurrent.futures.as_completed(future_to_doi):
                    doi = future_to_doi[future]
                    try:
                        data = future.result()
                        results[doi] = data
                    except Exception:
                        results[doi] = {}
        
        return results
    
    def _get_single_openalex_data(self, doi: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ DOI –∏–∑ OpenAlex"""
        if doi in self._openalex_cache:
            return self._openalex_cache[doi]
            
        try:
            url = f"https://api.openalex.org/works/https://doi.org/{doi}"
            response = self.session.get(url, timeout=15)
            if response.status_code == 200:
                data = response.json()
                self._openalex_cache[doi] = data
                return data
        except Exception as e:
            st.warning(f"OpenAlex error for {doi}: {e}")
            
        return {}
    
    def extract_authors(self, crossref_data: Dict, openalex_data: Dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–≤—Ç–æ—Ä–æ–≤"""
        authors = []
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º OpenAlex (–æ–±—ã—á–Ω–æ –ª—É—á—à–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω—ã)
        if openalex_data and 'authorships' in openalex_data:
            for authorship in openalex_data['authorships']:
                author_name = authorship.get('author', {}).get('display_name', '')
                if author_name:
                    authors.append(author_name)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ OpenAlex, –ø—Ä–æ–±—É–µ–º Crossref
        if not authors and crossref_data and 'author' in crossref_data:
            for author in crossref_data['author']:
                given = author.get('given', '')
                family = author.get('family', '')
                if given or family:
                    authors.append(f"{given} {family}".strip())
        
        return ', '.join(authors) if authors else 'Unknown'
    
    def extract_journal_info(self, crossref_data: Dict) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∂—É—Ä–Ω–∞–ª–µ"""
        try:
            container_title = crossref_data.get('container-title', [])
            short_container_title = crossref_data.get('short-container-title', [])
            
            full_name = container_title[0] if container_title else (
                short_container_title[0] if short_container_title else 'Unknown'
            )
            abbreviation = short_container_title[0] if short_container_title else (
                container_title[0] if container_title else 'Unknown'
            )
            
            return {
                'full_name': full_name,
                'abbreviation': abbreviation,
                'publisher': crossref_data.get('publisher', 'Unknown')
            }
        except:
            return {
                'full_name': 'Unknown',
                'abbreviation': 'Unknown',
                'publisher': 'Unknown'
            }
    
    def extract_year(self, crossref_data: Dict, openalex_data: Dict) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        # –ü—Ä–æ–±—É–µ–º OpenAlex
        if openalex_data and openalex_data.get('publication_year'):
            return str(openalex_data['publication_year'])
        
        # –ü—Ä–æ–±—É–µ–º Crossref
        for key in ['published-print', 'published-online', 'issued']:
            if key in crossref_data and 'date-parts' in crossref_data[key]:
                date_parts = crossref_data[key]['date-parts'][0]
                if date_parts and len(date_parts) > 0:
                    return str(date_parts[0])
        
        return 'Unknown'
    
    def get_article_data_batch(self, dois: List[str]) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Å—Ç–∞—Ç—å—è—Ö –¥–ª—è —Å–ø–∏—Å–∫–∞ DOI"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        results = {}
        dois_to_fetch = []
        
        for doi in dois:
            if doi in self._article_data_cache:
                results[doi] = self._article_data_cache[doi]
            else:
                dois_to_fetch.append(doi)
        
        if not dois_to_fetch:
            return results
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Crossref –∏ OpenAlex
        with st.spinner("Fetching article data from APIs..."):
            crossref_results = self.get_crossref_data_batch(dois_to_fetch)
            time.sleep(self.request_delay)
            openalex_results = self.get_openalex_data_batch(dois_to_fetch)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        for doi in dois_to_fetch:
            crossref_data = crossref_results.get(doi, {})
            openalex_data = openalex_results.get(doi, {})
            
            title = 'Unknown'
            if openalex_data and openalex_data.get('title'):
                title = openalex_data['title']
            elif crossref_data.get('title'):
                title_list = crossref_data['title']
                if title_list:
                    title = title_list[0]
            
            authors = self.extract_authors(crossref_data, openalex_data)
            journal_info = self.extract_journal_info(crossref_data)
            year = self.extract_year(crossref_data, openalex_data)
            
            # –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            citation_count_crossref = crossref_data.get('is-referenced-by-count', 0)
            citation_count_openalex = openalex_data.get('cited_by_count', 0)
            
            article_data = {
                'doi': doi,
                'title': title,
                'authors': authors,
                'year': year,
                'journal_full_name': journal_info['full_name'],
                'journal_abbreviation': journal_info['abbreviation'],
                'publisher': journal_info['publisher'],
                'citation_count_crossref': citation_count_crossref,
                'citation_count_openalex': citation_count_openalex
            }
            
            results[doi] = article_data
            self._article_data_cache[doi] = article_data
        
        return results
    
    def get_references_batch(self, doi_list: List[str]) -> Dict[str, List[Dict]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ DOI"""
        all_references = {}
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ Crossref
        crossref_data = self.get_crossref_data_batch(doi_list)
        
        for doi in doi_list:
            data = crossref_data.get(doi, {})
            references = data.get('reference', [])
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            all_references[doi] = references[:self.max_references_per_article]
        
        return all_references
    
    def get_citing_articles_batch(self, doi_list: List[str]) -> Dict[str, List[str]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Å—Ç–∞—Ç—å–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ DOI"""
        all_citing_articles = {}
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ OpenAlex –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
        openalex_data = self.get_openalex_data_batch(doi_list)
        
        for doi in doi_list:
            citing_dois = []
            data = openalex_data.get(doi, {})
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAlex –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            if data and 'cited_by_count' in data and data['cited_by_count'] > 0:
                work_id = data.get('id', '').split('/')[-1]
                if work_id:
                    try:
                        citing_url = f"https://api.openalex.org/works?filter=cites:{work_id}&per-page={self.max_citations_per_article}"
                        response = self.session.get(citing_url, timeout=15)
                        if response.status_code == 200:
                            citing_data = response.json()
                            for work in citing_data.get('results', []):
                                if work.get('doi'):
                                    citing_dois.append(work['doi'])
                    except Exception as e:
                        st.warning(f"Error getting citations for {doi}: {e}")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            all_citing_articles[doi] = citing_dois[:self.max_citations_per_article]
        
        return all_citing_articles
    
    def analyze_references_fast(self, doi_list: List[str]) -> pd.DataFrame:
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫"""
        all_references_data = []
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Step 1/3: Getting source articles data...")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        source_articles_data = self.get_article_data_batch(doi_list)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for doi, data in source_articles_data.items():
            data['type'] = 'source'
            data['source_doi'] = doi
            all_references_data.append(data)
        
        progress_bar.progress(33)
        
        status_text.text("Step 2/3: Collecting references...")
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏
        all_references = self.get_references_batch(doi_list)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ DOI —Å—Å—ã–ª–æ–∫
        all_reference_dois = set()
        for references in all_references.values():
            for ref in references:
                ref_doi = ref.get('DOI')
                if ref_doi and self.validate_doi(ref_doi):
                    all_reference_dois.add(ref_doi)
        
        progress_bar.progress(66)
        
        status_text.text("Step 3/3: Getting references data...")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫
        if all_reference_dois:
            reference_articles_data = self.get_article_data_batch(list(all_reference_dois))
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è —Å—Å—ã–ª–æ–∫
            for source_doi, references in all_references.items():
                for i, ref in enumerate(references):
                    ref_doi = ref.get('DOI')
                    if ref_doi and self.validate_doi(ref_doi):
                        ref_data = reference_articles_data.get(ref_doi, {})
                        if ref_data:
                            ref_data['type'] = 'reference'
                            ref_data['source_doi'] = source_doi
                            ref_data['position'] = i + 1
                            all_references_data.append(ref_data)
        
        progress_bar.progress(100)
        status_text.text("Analysis complete!")
        
        return pd.DataFrame(all_references_data)
    
    def analyze_citations_fast(self, doi_list: List[str]) -> pd.DataFrame:
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
        all_citations_data = []
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("Step 1/3: Getting source articles data...")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        source_articles_data = self.get_article_data_batch(doi_list)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for doi, data in source_articles_data.items():
            data['type'] = 'source'
            data['source_doi'] = doi
            all_citations_data.append(data)
        
        progress_bar.progress(33)
        
        status_text.text("Step 2/3: Collecting citations...")
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Å—Ç–∞—Ç—å–∏
        all_citing_articles = self.get_citing_articles_batch(doi_list)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ DOI —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π
        all_citing_dois = set()
        for citing_dois in all_citing_articles.values():
            all_citing_dois.update(citing_dois)
        
        progress_bar.progress(66)
        
        status_text.text("Step 3/3: Getting citations data...")
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö —Ü–∏—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π
        if all_citing_dois:
            citing_articles_data = self.get_article_data_batch(list(all_citing_dois))
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π
            for source_doi, citing_dois in all_citing_articles.items():
                for citing_doi in citing_dois:
                    if self.validate_doi(citing_doi):
                        citing_data = citing_articles_data.get(citing_doi, {})
                        if citing_data:
                            citing_data['type'] = 'citation'
                            citing_data['source_doi'] = source_doi
                            all_citations_data.append(citing_data)
        
        progress_bar.progress(100)
        status_text.text("Analysis complete!")
        
        return pd.DataFrame(all_citations_data)

def main():
    st.title("üìö Refs/Cits Analysis - Fast Version")
    st.markdown("‚ö° –£—Å–∫–æ—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫ –∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π")
    
    analyzer = FastCitationAnalyzer()
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        st.info("""
        –í–≤–µ–¥–∏—Ç–µ DOI —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        - 10.1234/abcd.1234
        - https://doi.org/10.1234/abcd.1234  
        - doi:10.1234/abcd.1234
        """)
        
        max_dois = st.slider("–ú–∞–∫—Å–∏–º—É–º DOI –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", 5, 50, 15)
        analyzer.max_dois = max_dois
        
        max_refs = st.slider("–ú–∞–∫—Å. —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é", 5, 50, 15)
        analyzer.max_references_per_article = max_refs
        
        max_cits = st.slider("–ú–∞–∫—Å. —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é", 5, 50, 15)
        analyzer.max_citations_per_article = max_cits
        
        st.markdown("---")
        st.markdown("### üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        st.markdown("""
        **–£—Å–∫–æ—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:**
        - –ü–∞–∫–µ—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ API
        - –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å
        - –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏–º–∏—Ç—ã
        """)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
    tab1, tab2, tab3 = st.tabs(["üì• –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö", "üîó –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫", "üìà –ê–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"])
    
    with tab1:
        st.header("–í–≤–æ–¥ DOI —Å—Ç–∞—Ç–µ–π")
        
        input_method = st.radio("–°–ø–æ—Å–æ–± –≤–≤–æ–¥–∞:", ["üìù –¢–µ–∫—Å—Ç", "üìÅ –§–∞–π–ª"])
        
        if input_method == "üìù –¢–µ–∫—Å—Ç":
            doi_input = st.text_area(
                "–í–≤–µ–¥–∏—Ç–µ DOI —Å—Ç–∞—Ç–µ–π:",
                height=150,
                placeholder="–í–≤–µ–¥–∏—Ç–µ DOI —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏:\n10.1038/s41586-023-06924-6\n10.1126/science.abl8921\n10.1016/j.cell.2023.08.012"
            )
            
            if st.button("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å DOI", key="validate"):
                if doi_input:
                    dois = analyzer.parse_doi_input(doi_input)
                    if dois:
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(dois)} –≤–∞–ª–∏–¥–Ω—ã—Ö DOI:")
                        for doi in dois:
                            st.write(f"- `{doi}`")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session state
                        st.session_state.dois = dois
                    else:
                        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö DOI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç.")
        
        else:
            uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å DOI", type=['txt', 'csv'])
            if uploaded_file:
                content = uploaded_file.getvalue().decode()
                dois = analyzer.parse_doi_input(content)
                if dois:
                    st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(dois)} –≤–∞–ª–∏–¥–Ω—ã—Ö DOI –≤ —Ñ–∞–π–ª–µ")
                    st.write("–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ DOI:")
                    for doi in dois[:10]:
                        st.write(f"- `{doi}`")
                    if len(dois) > 10:
                        st.write(f"... –∏ –µ—â–µ {len(dois) - 10} DOI")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session state
                    st.session_state.dois = dois
    
    with tab2:
        st.header("üîó –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫ (References)")
        
        if 'dois' in st.session_state and st.session_state.dois:
            dois = st.session_state.dois
            
            st.info(f"–ë—É–¥–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(dois)} —Å—Ç–∞—Ç–µ–π (–º–∞–∫—Å–∏–º—É–º {analyzer.max_references_per_article} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å—é)")
            
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫", type="primary"):
                if not dois:
                    st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ –≤–∞–ª–∏–¥–Ω—ã–µ DOI –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö'")
                else:
                    with st.spinner("‚ö° –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫..."):
                        references_df = analyzer.analyze_references_fast(dois)
                    
                    if not references_df.empty:
                        st.success("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                        
                        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            total_refs = len(references_df[references_df['type'] == 'reference'])
                            st.metric("–í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫", total_refs)
                        with col2:
                            unique_journals = references_df['journal_abbreviation'].nunique()
                            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∂—É—Ä–Ω–∞–ª–æ–≤", unique_journals)
                        with col3:
                            source_articles = len(references_df[references_df['type'] == 'source'])
                            st.metric("–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π", source_articles)
                        with col4:
                            avg_citations = references_df['citation_count_openalex'].mean()
                            st.metric("–°—Ä–µ–¥–Ω–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è", f"{avg_citations:.1f}")
                        
                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≥–æ–¥–∞–º
                        st.subheader("üìÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º")
                        year_counts = references_df[references_df['year'] != 'Unknown']['year'].value_counts()
                        if not year_counts.empty:
                            st.bar_chart(year_counts.head(10))
                        
                        # –î–∞–Ω–Ω—ã–µ
                        st.subheader("üìã –î–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–æ–∫")
                        
                        # –§–∏–ª—å—Ç—Ä—ã
                        col1, col2 = st.columns(2)
                        with col1:
                            show_type = st.selectbox("–¢–∏–ø –∑–∞–ø–∏—Å–µ–π:", ["–í—Å–µ", "–¢–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ", "–¢–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏"])
                        with col2:
                            show_columns = st.multiselect(
                                "–ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                                references_df.columns,
                                default=['doi', 'title', 'authors', 'year', 'journal_abbreviation', 'citation_count_openalex']
                            )
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
                        filtered_df = references_df
                        if show_type == "–¢–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ":
                            filtered_df = references_df[references_df['type'] == 'source']
                        elif show_type == "–¢–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏":
                            filtered_df = references_df[references_df['type'] == 'reference']
                        
                        if show_columns:
                            filtered_df = filtered_df[show_columns]
                        
                        st.dataframe(filtered_df, use_container_width=True)
                        
                        # –≠–∫—Å–ø–æ—Ä—Ç
                        st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
                        csv = references_df.to_csv(index=False)
                        st.download_button(
                            "üì• –°–∫–∞—á–∞—Ç—å CSV",
                            csv,
                            "references_analysis.csv",
                            "text/csv",
                            key='download_refs'
                        )
                    else:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        else:
            st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ DOI –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö'")
    
    with tab3:
        st.header("üìà –ê–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π (Citations)")
        
        if 'dois' in st.session_state and st.session_state.dois:
            dois = st.session_state.dois
            
            st.info(f"–ë—É–¥–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(dois)} —Å—Ç–∞—Ç–µ–π (–º–∞–∫—Å–∏–º—É–º {analyzer.max_citations_per_article} —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –Ω–∞ —Å—Ç–∞—Ç—å—é)")
            
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π", type="primary"):
                if not dois:
                    st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ –≤–∞–ª–∏–¥–Ω—ã–µ DOI –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö'")
                else:
                    with st.spinner("‚ö° –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —É—Å–∫–æ—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π..."):
                        citations_df = analyzer.analyze_citations_fast(dois)
                    
                    if not citations_df.empty:
                        st.success("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                        
                        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            total_cits = len(citations_df[citations_df['type'] == 'citation'])
                            st.metric("–í—Å–µ–≥–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π", total_cits)
                        with col2:
                            citing_journals = citations_df[citations_df['type'] == 'citation']['journal_abbreviation'].nunique()
                            st.metric("–¶–∏—Ç–∏—Ä—É—é—â–∏—Ö –∂—É—Ä–Ω–∞–ª–æ–≤", citing_journals)
                        with col3:
                            source_articles = len(citations_df[citations_df['type'] == 'source'])
                            st.metric("–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π", source_articles)
                        with col4:
                            recent_year = str(pd.Timestamp.now().year)
                            recent_citations = len(citations_df[
                                (citations_df['type'] == 'citation') & 
                                (citations_df['year'] == recent_year)
                            ])
                            st.metric(f"–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π {recent_year}", recent_citations)
                        
                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≥–æ–¥–∞–º
                        st.subheader("üìÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º")
                        year_counts = citations_df[citations_df['year'] != 'Unknown']['year'].value_counts()
                        if not year_counts.empty:
                            st.bar_chart(year_counts.head(10))
                        
                        # –î–∞–Ω–Ω—ã–µ
                        st.subheader("üìã –î–∞–Ω–Ω—ã–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
                        
                        # –§–∏–ª—å—Ç—Ä—ã
                        col1, col2 = st.columns(2)
                        with col1:
                            show_type = st.selectbox("–¢–∏–ø –∑–∞–ø–∏—Å–µ–π:", ["–í—Å–µ", "–¢–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ", "–¢–æ–ª—å–∫–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"], key='cit_type')
                        with col2:
                            show_columns = st.multiselect(
                                "–ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                                citations_df.columns,
                                default=['doi', 'title', 'authors', 'year', 'journal_abbreviation', 'citation_count_openalex'],
                                key='cit_columns'
                            )
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
                        filtered_df = citations_df
                        if show_type == "–¢–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ":
                            filtered_df = citations_df[citations_df['type'] == 'source']
                        elif show_type == "–¢–æ–ª—å–∫–æ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è":
                            filtered_df = citations_df[citations_df['type'] == 'citation']
                        
                        if show_columns:
                            filtered_df = filtered_df[show_columns]
                        
                        st.dataframe(filtered_df, use_container_width=True)
                        
                        # –≠–∫—Å–ø–æ—Ä—Ç
                        st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
                        csv = citations_df.to_csv(index=False)
                        st.download_button(
                            "üì• –°–∫–∞—á–∞—Ç—å CSV",
                            csv,
                            "citations_analysis.csv",
                            "text/csv",
                            key='download_cits'
                        )
                    else:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        else:
            st.warning("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –≤–≤–µ–¥–∏—Ç–µ DOI –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö'")

if __name__ == "__main__":
    main()
